name: CD (Deploy to Yandex VPS)

on:
  workflow_run:
    workflows: ["CI (Local tests)"]
    types: [completed]
  workflow_dispatch:

jobs:
  deploy:
    name: Deploy
    runs-on: ubuntu-22.04
    if: |
      (github.event_name == 'workflow_run' &&
       github.event.workflow_run.conclusion == 'success' &&
       github.event.workflow_run.event == 'push' &&
       (github.event.workflow_run.head_branch == 'main' || github.event.workflow_run.head_branch == 'dev/hw3')) ||
      (github.event_name == 'workflow_dispatch')

    steps:
      - name: Set ref/branch for checkout
        shell: bash
        run: |
          set -euo pipefail
          if [ "${{ github.event_name }}" = "workflow_run" ]; then
            echo "CHECKOUT_REF=${{ github.event.workflow_run.head_sha }}" >> "$GITHUB_ENV"
            echo "DEPLOY_BRANCH=${{ github.event.workflow_run.head_branch }}" >> "$GITHUB_ENV"
          else
            echo "CHECKOUT_REF=${{ github.sha }}" >> "$GITHUB_ENV"
            echo "DEPLOY_BRANCH=${{ github.ref_name }}" >> "$GITHUB_ENV"
          fi

      - uses: actions/checkout@v4
        with:
          ref: ${{ env.CHECKOUT_REF }}

      - name: Detect project base dir
        id: detect
        shell: bash
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import pathlib, os
          root = pathlib.Path(".").resolve()

          base = None
          for p in root.rglob("api-gateway/docker-compose.yaml"):
            if ".git" in p.parts:
              continue
            base = p.parent.parent
            break

          if base is None:
            raise SystemExit("Cannot find api-gateway/docker-compose.yaml in repo")

          rel = str(base.relative_to(root))
          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
            f.write(f"base={rel}\n")
          print("Detected base:", rel)
          PY

      - name: Prepare SSH
        shell: bash
        env:
          HOST: ${{ secrets.DEPLOY_HOST }}
          KEY:  ${{ secrets.DEPLOY_SSH_KEY }}
        run: |
          set -euo pipefail
          mkdir -p ~/.ssh
          printf "%s" "$KEY" > ~/.ssh/id_ed25519
          chmod 600 ~/.ssh/id_ed25519
          ssh-keyscan -H "$HOST" >> ~/.ssh/known_hosts

      - name: Rsync code to server
        shell: bash
        env:
          HOST: ${{ secrets.DEPLOY_HOST }}
          USER: ${{ secrets.DEPLOY_USER }}
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y rsync

          if [ "${DEPLOY_BRANCH}" = "main" ]; then
            REMOTE_DIR="/opt/anti-plagiarism/prod"
          else
            REMOTE_DIR="/opt/anti-plagiarism/dev"
          fi
          echo "REMOTE_DIR=$REMOTE_DIR" >> "$GITHUB_ENV"

          ssh -i ~/.ssh/id_ed25519 -o IdentitiesOnly=yes -o StrictHostKeyChecking=no \
            "${USER}@${HOST}" "sudo mkdir -p '${REMOTE_DIR}/repo' && sudo chown -R '${USER}:${USER}' '/opt/anti-plagiarism'"

          rsync -az --delete \
            -e "ssh -i ~/.ssh/id_ed25519 -o IdentitiesOnly=yes -o StrictHostKeyChecking=no" \
            --exclude ".git" \
            --exclude ".DS_Store" \
            --exclude "__MACOSX" \
            "./" "${USER}@${HOST}:${REMOTE_DIR}/repo"

      - name: Deploy (validate compose + docker compose up)
        shell: bash
        env:
          HOST: ${{ secrets.DEPLOY_HOST }}
          USER: ${{ secrets.DEPLOY_USER }}
          BASE: ${{ steps.detect.outputs.base }}
          S3_ENV: ${{ secrets.S3_ENV }}
          YANDEX_CLOUD_ENV: ${{ secrets.YANDEX_CLOUD_ENV }}
        run: |
          set -euo pipefail

          S3_B64="$(printf "%s" "${S3_ENV:-}" | base64 -w0)"
          YC_B64="$(printf "%s" "${YANDEX_CLOUD_ENV:-}" | base64 -w0)"

          ssh -i ~/.ssh/id_ed25519 -o IdentitiesOnly=yes -o StrictHostKeyChecking=no \
            "${USER}@${HOST}" "REMOTE_DIR='${REMOTE_DIR}' BASE='${BASE}' S3_B64='${S3_B64}' YC_B64='${YC_B64}' bash -s" <<'SCRIPT'
          set -euo pipefail

          cd "$REMOTE_DIR/repo/$BASE"

          if [ -n "${S3_B64:-}" ]; then
            mkdir -p file-storing/internal/env-files
            printf "%s" "$S3_B64" | base64 -d > file-storing/internal/env-files/s3.env
          fi

          if [ -n "${YC_B64:-}" ]; then
            mkdir -p embedding-service/internal/env-files
            printf "%s" "$YC_B64" | base64 -d > embedding-service/internal/env-files/yandexCloud.env
          fi

          sudo -n docker version >/dev/null
          sudo -n docker compose version >/dev/null

          validate() {
            local f="$1"
            if [ -f "$f" ]; then
              echo "== Validating: $f =="
              # Это поймает ошибки типа environment: - (nil)
              sudo -n docker compose -f "$f" config >/dev/null
            fi
          }

          validate "./docker-compose.yaml"
          validate "./embedding-service/docker-compose.yaml"
          validate "./file-storing/docker-compose.yaml"
          validate "./file-analisys/docker-compose.yaml"
          validate "./api-gateway/docker-compose.yaml"

          if [ -f docker-compose.yaml ]; then
            sudo -n docker compose up -d --build
          fi

          (cd embedding-service && sudo -n docker compose up -d --build)
          (cd file-storing && sudo -n docker compose up -d --build)
          (cd file-analisys && sudo -n docker compose up -d --build)
          (cd api-gateway && sudo -n docker compose up -d --build)

          sudo -n docker image prune -f >/dev/null 2>&1 || true
          SCRIPT

  integration-tests:
    name: Integration tests (after deploy)
    runs-on: ubuntu-22.04
    needs: [deploy]
    if: ${{ needs.deploy.result == 'success' }}

    steps:
      - name: Set ref for checkout
        shell: bash
        run: |
          set -euo pipefail
          if [ "${{ github.event_name }}" = "workflow_run" ]; then
            echo "CHECKOUT_REF=${{ github.event.workflow_run.head_sha }}" >> "$GITHUB_ENV"
          else
            echo "CHECKOUT_REF=${{ github.sha }}" >> "$GITHUB_ENV"
          fi

      - uses: actions/checkout@v4
        with:
          ref: ${{ env.CHECKOUT_REF }}

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Detect tests dir (py_dir)
        id: detect_py
        shell: bash
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import os, pathlib
          root = pathlib.Path(".").resolve()

          py_dir = ""
          for p in root.rglob("api-gateway/go.mod"):
            if ".git" in p.parts:
              continue
            anti = p.parent.parent
            t = anti / "tests"
            if t.exists():
              py_dir = str(t.relative_to(root))
            break

          with open(os.environ["GITHUB_OUTPUT"], "a") as f:
            f.write(f"py_dir={py_dir}\n")

          print("py_dir =", py_dir)
          PY

      - name: Wait for gateway /health
        shell: bash
        env:
          API_GATEWAY_URL: http://${{ secrets.DEPLOY_HOST }}:8080
        run: |
          set -euo pipefail
          url="${API_GATEWAY_URL}/health"
          echo "Waiting for $url ..."
          for i in $(seq 1 60); do
            code="$(curl -s -o /tmp/health.json -w "%{http_code}" "$url" || true)"
            if [ "$code" = "200" ]; then
              cat /tmp/health.json || true
              echo "Health OK"
              exit 0
            fi
            echo "Attempt $i/60: HTTP $code"
            sleep 5
          done
          echo "Health check failed (timeout)"
          echo "Last response:"
          cat /tmp/health.json || true
          exit 1

      - name: Run integration E2E (full flow)
        if: ${{ steps.detect_py.outputs.py_dir != '' }}
        shell: bash
        env:
          API_GATEWAY_URL: http://${{ secrets.DEPLOY_HOST }}:8080
        run: |
          set -euo pipefail
          RUN_FULL_FLOW=1 API_GATEWAY_URL="${API_GATEWAY_URL}" \
            python -m unittest discover -s "${{ steps.detect_py.outputs.py_dir }}" -p "test_*.py" -v
